{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b7ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification d'images avec CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29381303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les CNN sont globalement de meilleurs réseaux pour les\n",
    "# traitements nécessitant beaucoup de paramètres (surtout\n",
    "# pour les images) car ils apprennent les motifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8032ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noyaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb8b3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les noyaux de convolution, sont de petites matrices de poids\n",
    "# apprenables servant à détecter les motifs dans l'image.\n",
    "# Ils permettent de détecter :\n",
    "# - Contours\n",
    "# - Textures\n",
    "# - Formes\n",
    "# - Caractéristiques complexes\n",
    "\n",
    "# Ils s'organisent de manière hiérarchique :\n",
    "# - Premières couches : détection de caractéristiques simples \n",
    "# - Couches intermédiaires : combinent les caractéristiques pour\n",
    "# détecter les formes\n",
    "# - Couches profondes : détectent les objets complexes (comme :\n",
    "# visages, voitures, animaux...)\n",
    "\n",
    "# L'entraînement détermine la spécialisation du noyau :\n",
    "# Initialisation aléatoire : noyaux avec valeurs proches de 0\n",
    "# Apprentissage automatique : descente de gradient ajuste les poids\n",
    "# Spécialisation émergente : apprend à détecter les motifs les plus\n",
    "# utiles pour la tâche.\n",
    "# Pas de programmation manuelle : le réseau découvre lui-même quels\n",
    "# motifs sont importants.\n",
    "\n",
    "# Les convolutions ont plusieurs avantages :\n",
    "# - Partage de poids : Le même filtre est appliqué sur l'image, \n",
    "# permettant de réduire le # de paramètres\n",
    "# - Invariance par translation : un motif appris peut être repéré\n",
    "# partout sur l'image.\n",
    "# - Préservation de la structure spatiale : les convolutions\n",
    "# traitent des régions locales, préservant les relations entre\n",
    "# pixels voisins.\n",
    "\n",
    "# Avec PyTorch :\n",
    "# Voir chapitre 4, exercice 4\n",
    "\n",
    "# Calcul de la taille de sortie\n",
    "# H_out = ⌊ (H_in + 2 × padding - kernel_size) ÷ stride ⌋ + 1\n",
    "# Si en entrée j'ai une image de 224 × 224, il faut que (par exemple):\n",
    "# padding = 1, kernel_size = 3, stride = 1.\n",
    "# Il faut que la taille de l'image en sortie soit la même que la taille\n",
    "# de l'image en entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3071165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les couches de pooling permettent de réduire progressivement la \n",
    "# taille spaciale des représentations :\n",
    "# Permet de diminuer le nombre de paramètres et le temps de calcul\n",
    "# Apporte une invariance aux petites translations\n",
    "# Augmente le champ réceptif.\n",
    "\n",
    "# Le max pooling garde la valeur max d'une région d'une image (la \n",
    "# région étant de dimensions hauteur_image / 2 par largeur_image / 2)\n",
    "\n",
    "# L'average pooling calcule la moyenne de chaque région"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a0bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c68452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'entraînement par mini-batchs est fondamental en DL, combinant\n",
    "# les avantages de deux techniques extrêmes.\n",
    "\n",
    "# Trois approches :\n",
    "# Batch Gradient Descent, calcule le gradient sur toutes les données\n",
    "# mise à jour lente et nécessitant beaucoup de mémoire.\n",
    "# Stochastic Gradient Descent (SGD), calcule le gradient d'un seul\n",
    "# exemple, donc gradient bruité et converge erratiquement.\n",
    "# Mini-Batch Gradient Descent, calcule le gradient pour un petit\n",
    "# groupe de d'exemples, rapide et plutôt stable, exploite le GPU.\n",
    "\n",
    "# Choix de la taille :\n",
    "# Petits batchs (16-32), + de bruit, convergence plus exploratrice.\n",
    "# Grands batchs (128-256), + stables, convergence plus directe.\n",
    "# Compromis courants : 32 ou 64\n",
    "\n",
    "# Avec PyTorch :\n",
    "# Voir chapitres 3 & 4, exercices 1 & 2 et exercice 4 respectivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f88a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les poids d'un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Après avoir entraîné son modèle (ce qui peut prendre des heures),\n",
    "# il est important de le sauvegarder pour pouvoir le réutiliser sans\n",
    "# avoir à r'entraîner.\n",
    "\n",
    "# Avec PyTorch :\n",
    "from torch import save, load\n",
    "\n",
    "# Remplacer model par son modèle à enregistrer\n",
    "save(model, 'model_complet.pth')\n",
    "\n",
    "# Charger le modèle\n",
    "model = load('model_complet.pth')\n",
    "model.eval()\n",
    "\n",
    "# Cette méthode de sauvegarde peut poser problème si vous changez la \n",
    "# définition de la classe après l'avoir sauvegardé.\n",
    "\n",
    "# Sauvegarder uniquement les poids :\n",
    "save(model.state_dict(), 'model_poids.pth')\n",
    "\n",
    "# Avantages : on peut modifier légèrement le modèle après l'avoir \n",
    "# enregistré.\n",
    "state_dict = load('model_poids.pth')\n",
    "del state_dict['fc2.weight'], state_dict['fc2.bias'] # Suppression des\n",
    "# poids incompatibles.\n",
    "model.state_dict(state_dict, strict=False) # strict=False permet\n",
    "# d'ignorer les couches manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf4daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e61d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
