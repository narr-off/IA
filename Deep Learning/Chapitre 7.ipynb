{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e089fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc67c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les hyper-paramètres sont des valeurs fixées avant l'entraînement,\n",
    "# influençant la performance, la stabilité et la vitesse de convergence\n",
    "# du modèle. Contrairement aux paramètres appris, les hyper-paramètres\n",
    "# nécessitent maîtrise et expérimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1434455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bfa038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'early stopping consiste à arrêter l'entraînement quand les performances\n",
    "# d'un modèle sur le jeu de validation cessent de s'améliorer. Il permet\n",
    "# aussi d'éviter le surapprentissage.\n",
    "\n",
    "# Avec PyTorch :\n",
    "# Voir chapitre 3, exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a81adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeab109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le learning rate influence la vitesse d'apprentissage d'un modèle.\n",
    "# Le scheduler permet de modifier sa valeur selon une stratégie.\n",
    "# Réduire le learning rate durant l'entraînement améliore souvent la \n",
    "# convergence et la performance du modèle.\n",
    "# Plusieurs stratégies :\n",
    "# - Réduction par palier\n",
    "# - Réduction exponentielle\n",
    "# - Basé sur la performance (patience)\n",
    "\n",
    "# Avec PyTorch\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, ExponentialLR, CosineAnnealingLR, LinearLR\n",
    "from torch.nn import Module, Linear, ReLU\n",
    "from torch.optim import SGD\n",
    "\n",
    "class MLP(Module):\n",
    "  def __init__(self, features, neurons, classes):\n",
    "    super(MLP, self).__init__()\n",
    "    self.fc1 = Linear(features, neurons)\n",
    "    self.fc2 = Linear(neurons, classes)\n",
    "    self.relu = ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.relu(self.fc1(x))\n",
    "    return self.fc2(x)\n",
    "\n",
    "model = MLP()\n",
    "optimizer = SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Step scheduler, réduit à intervalles fixes \n",
    "step = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# ReduceLROnPlateau, réduction basée sur la patience\n",
    "plateau_sch = ReduceLROnPlateau(optimizer, factor=0.5, patience=3)\n",
    "\n",
    "# Exponential scheduler, réduction exponentielle\n",
    "exp_sch = ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "# Cos scheduler, réduction cosinusoïdale\n",
    "cos_sch = CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "# Réduction linéaire\n",
    "lin_sch = LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=100)\n",
    "\n",
    "# Utilisation dans la boucle d'entraînement\n",
    "for _ in range(50):\n",
    "  # Toutes les étapes précédentes, et après optimizer.step():\n",
    "  # Le nom du scheduler\n",
    "  # scheduler.step(loss)\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66183c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445de5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le moment (momentum), est une technique complémentaire aidant \n",
    "# à accélérer la convergence en accumulant une \"vitesse\" (inertie)\n",
    "# dans la direction des gradients. Tous les optimisateurs basés sur \n",
    "# le gradient peuvent intégrer le momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les régularisateurs pénalisent la complexité du modèle en ajoutant\n",
    "# une contrainte aux poids. Cela permet d'éviter l'overfitting, en\n",
    "# limitant la complexité du modèle à s'adapter trop étroitement aux\n",
    "# données d'entrainement.\n",
    "\n",
    "# Les régularisations les plus courantes sont :\n",
    "# - L2 Regularisation (Ridge) : pénalise la somme des carrés des poids,\n",
    "# encourageant des poids plus petits et répartis.\n",
    "# - L1 Regularisation (Lasso) : pénalise la somme des valeurs absolues\n",
    "# des poids, favorisant la sparité (beaucoup de poids = 0)\n",
    "# - Dropout : éteint aléatoirement certains neurones (améliore la \n",
    "# généralisation).\n",
    "\n",
    "# Régularisation L2\n",
    "# L_total = L_original + λ·∑i -> w_i²\n",
    "# où L_total est la nouvelle fonction de perte avec régularisation, \n",
    "# L_original la fonction de perte originale, λ le coefficient de\n",
    "# régularisation, w_i représente les poids du modèle.\n",
    "\n",
    "# Avec PyTorch\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=1e-2, weight_decay=1e-3)\n",
    "\n",
    "# Regularisation L1\n",
    "# L_total = L_original + λ·∑i -> |w_i|\n",
    "# Cette régularisation favorise les poids = 0, ce qui peut être utile\n",
    "# pour sélectionner automatiquement les caractéristiques les plus\n",
    "# importantes dans les données.\n",
    "\n",
    "# Pas d'implémentation avec PyTorch :\n",
    "λ = 1e-3\n",
    "criterion = MSELoss()\n",
    "\n",
    "for _ in range(50):\n",
    "  optimizer.zero_grad()\n",
    "  loss = criterion(model(input), \"target\") # Target mis en commentaires\n",
    "  # éviter les erreurs.\n",
    "\n",
    "  # Ajout de la régularisation L1\n",
    "  l1 = sum(p.abs().sum() for p in model.parameters())\n",
    "  loss = loss + λ * l1\n",
    "  \n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "# Dropout\n",
    "# y_i {z_i avec probabilité 1-p et 0 avec probabilité p\n",
    "# où y_i est la sortie du neurone, z_i est la sortie initiale du neurone\n",
    "# et p la probabilité de dropout.\n",
    "# Le Dropout est utile pour éviter la co-adaptation des poids ce qui \n",
    "# améliore la généralisation du modèle.\n",
    "\n",
    "# Avec PyTorch :\n",
    "# Dans la classe du MLP/CNN, etc, déclarer dans le __init__ :\n",
    "# self.drop = Dropout(0.5), 0.5 représentant p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116aeaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les réseaux de neurones sont sensibles aux distributions de données, à leur\n",
    "# domaine de valeur. Il y a deux distributions de données :\n",
    "# - In-distribution (ID), données que le modèle à l'habitude de voir et de traiter\n",
    "# - Out-of-distribution (OOD), l'inverse du précédent.\n",
    "# Le changement de distribution interne est appelé le internal covariate shift\n",
    "# (décalage des covariables internes, ou ICS/DCI), et peut ralentir l'entraînement.\n",
    "\n",
    "# Normalizers pour contrer le DCI\n",
    "# ̂x = (x-μ(x)) ÷ (σ(x)+ε) × γ + β\n",
    "# où ̂x est la valeur standardisée, x est la valeur d'entrée, μ(x) est la moyenne des\n",
    "# activations, σ(x) est l'écart-type des activations, ε est une petite constante\n",
    "# pour éviter la division par 0, γ et β sont des paramètres appris qui permettent\n",
    "# de redimmentionner et de recentrer les activations standardisées.\n",
    "\n",
    "# Il existe plusieurs normalizers, qui diffèrent dans la manière de calculer μ(x)\n",
    "# et σ(x) ainsi que le moment où ils sont appliqués dans le réseau.\n",
    "# Les plus courants :\n",
    "# - Batch Normalization : standardise sur un mini-batch de données, aidant à stabiliser\n",
    "# et accélérer l'entraînement.\n",
    "# - Layer Normalisation : standardise sur toutes les caractéristiques d'une seule donnée,\n",
    "# utile pour les architectures récurrentes.\n",
    "# - Instance Normalization : standardise sur chaque canal d'une donnée. Utilisé en cv\n",
    "# - Group Normalization : divise les canaux en groupes et standardise les activations\n",
    "# au sein de chaque groupe. Utile lorsque la taille du batch est petite.\n",
    "\n",
    "# Avec Pytorch\n",
    "from torch.nn import BatchNorm2d, LayerNorm, InstanceNorm2d, GroupNorm\n",
    "\n",
    "class ImageNormalizerNetwork(Module):\n",
    "  def __init__(self):\n",
    "    super(ImageNormalizerNetwork, self).__init__()\n",
    "    self.batch = BatchNorm2d(3) # 3 canaux pour tout le batch\n",
    "    self.layer = LayerNorm([3, 224, 224]) # chaque échantillon\n",
    "    self.inst = InstanceNorm2d(3) # chaque canal\n",
    "    self.group = GroupNorm(1, 3) # 1 groupe pour 3 canaux\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # Appeler les fonctions ci-dessus pour effectuer la standardisation.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b0e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search/tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf57bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D'autres hyper-paramètres, différents que ceux que nous avons vu,\n",
    "# sont importants, comme :\n",
    "# - Le choix de l'optimisateur\n",
    "# - Le learning rate initial\n",
    "# - La taille du batch\n",
    "# - L'architecture du modèle\n",
    "\n",
    "# En Deep Learning, il nous faut trouver une combinaison optimale de \n",
    "# ces paramètres. La recherche d'hyper-paramètres est le processus\n",
    "# d'optimisation de ces derniers, pour améliorer les performances\n",
    "# d'un modèle. \n",
    "# Les stratégies les plus communes sont au nombre de 4 :\n",
    "# - Grid Search : exploration exhaustive d'une grille prédéfinie d'hyper-\n",
    "# paramètres, méthode simple mais coûteuse.\n",
    "# - Random Search : souvent plus efficace que la recherche en grille, \n",
    "# surtout lorsque des hyper-paramètres ont plus d'impact que d'autres.\n",
    "# - Bayezian Optimization : utilise des modèles probabilistes pour\n",
    "# modéliser la fonction de performance, guide la recherche des paramètres\n",
    "# vers les régions prometteuses de l'espace hyper-paramétrique.\n",
    "# - Hyperband : combine recherche aléatoire avec early stopping pour\n",
    "# allouer les ressources de calcul aux configurations les plus prometteuses.\n",
    "\n",
    "# Quelques bibliothèques :\n",
    "# - Optuna\n",
    "# - Hyperopt\n",
    "# - Ray Tune\n",
    "# - Scikit-Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
